# Jovix Gateway — 本地端多模態 I/O 閘道器

> 狀態：📋 規劃中
> 目標：把 Jovix (5080) 變成「可接機器人」的本地 AI 系統

## 一句話定義

手機當遙控器 + 感測器，Jovix (5080) 當推理/處理機，OpenClaw 當大腦與行動編排。

## 為什麼不用 Gemini / ChatGPT Voice？

不是要打敗大廠，而是拿到這些能力：

| 能力 | Gemini | Jovix Gateway |
|------|--------|---------------|
| 隱私 | 資料上雲 | 本地處理（可選上雲） |
| 可插拔 | 黑盒子 | 今天 Whisper，明天換別的 |
| 可上身體 | ❌ | 接遙控車/機器人/家電 |
| 可寫規則 | 有限 | 完全自訂 |

**核心價值：這是「你的作業系統」，不是別人的服務。**

## 系統架構（4 層）

```
┌─────────────────────────────────────────────────────────┐
│  Layer A: 手機端（感測器 + UI）                          │
│  - 麥克風音訊、相機畫面、觸控指令                        │
│  - 接收：文字/語音回覆、狀態、控制面板                   │
└─────────────────────────────────────────────────────────┘
                            ↓ WebSocket
┌─────────────────────────────────────────────────────────┐
│  Layer B: Jovix 5080（重活）                             │
│  - 視覺：YOLO/Seg、OCR、追蹤                            │
│  - 影像生成：ComfyUI                                    │
│  - (語音可外包給 OpenClaw 內建)                          │
└─────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Layer C: OpenClaw / Agent（決策層）                     │
│  - 意圖解析 + 工具呼叫                                  │
│  - 工作流編排                                           │
└─────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Layer D: 行動層                                         │
│  - 軟體：跑腳本、控制 ComfyUI、整理檔案                 │
│  - 硬體：遙控車 / ESP32 / Raspberry Pi（Wi-Fi）         │
└─────────────────────────────────────────────────────────┘
```

## MVP 優先順序

### MVP-1：語音對話（可能不用自己做）
```
手機語音訊息 → OpenClaw 內建轉錄 → Agent 回覆 → 手機顯示
```
- OpenClaw 已有 voice notes 支援
- 可能直接用 Telegram/WhatsApp 就行
- **5080 算力留給視覺**

### MVP-2：視覺問答（推薦先做）
```
手機拍照/每秒一張 → Jovix 視覺模型 → OpenClaw → 回答
```
- 成功條件：對著東西問「這是什麼」「把這個做成 icon 風格」
- **這才是 5080 的價值所在**

### MVP-3：遙控車閉環（最爽）
```
語音「往前 1 公尺」→ OpenClaw → HTTP/MQTT → 車子動
```
- 成功條件：語音 → 車動
- 等 pipeline 穩了再接硬體

## 技術選擇

| 層面 | 選擇 | 原因 |
|------|------|------|
| 手機 ↔ Jovix | WebSocket | 雙向、低延遲 |
| 視覺傳輸 | JPEG 抽幀 | 先穩再快，不要一開始就 WebRTC |
| 車子控制 | HTTP / MQTT | HTTP 直覺，MQTT 更 IoT |
| 語音 | OpenClaw 內建 | 不重造輪子 |

## 避坑指南

1. **「視訊」是大坑** — 先抽幀、低頻率，等穩了再升級
2. **GPU 不是萬靈丹** — 瓶頸常在 I/O、編碼、網路
3. **Agent 不要太聰明** — 先用明確 mode（控制車 / 問畫面 / 跑 ComfyUI）
4. **安全性** — 只用官方/看得懂原始碼的 plugin

## 核心 Deliverable

**不是模型，是「感知-指令協議」**

```json
{
  "intent": "ask_vision",
  "transcript": "這是什麼東西？",
  "frame_url": "http://...",
  "mode": "visual_qa",
  "timestamp": 1234567890
}
```

一旦協議定了，換模型、換硬體都只是 plug-in。

## 與其他專案的連結

### → Raijax
Jovix 可以用鏡頭參與 Raijax 的圖片競猜：
- 拍到東西 → 視覺分析 → 自己去 Raijax 玩
- **Human vs AI 的真實對決**

### → Jarvis
Jarvis（Mac Mini）專注文字/邏輯，Jovix 專注視覺/GPU：
- 分工協作的多 Agent 系統

## 下一步

- [ ] 測試 OpenClaw 語音能力（Jovix 收語音訊息）
- [ ] 設計 JSON schema（感知結果 + 工具呼叫）
- [ ] 選定 MVP-2 的視覺模型（YOLO? CLIP?）
- [ ] 寫一個接收圖片的 skill

---

*規劃日期：2026-02-06*
*由 Jones 與 GPT 討論，Jarvis 整理*
